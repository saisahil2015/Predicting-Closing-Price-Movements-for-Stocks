{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "XxUmEZtUbiAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A66jPTpYbcou"
      },
      "outputs": [],
      "source": [
        "!unzip \"/content/drive/MyDrive/optiver-trading-at-the-close.zip\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Code for Generating New Features Being Engineered for Training the Model"
      ],
      "metadata": {
        "id": "nBOZigNScUvB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#UNCOMMENT AND RUN THIS CODE TO CREATE .CSV FILE WITH NEWLY GENERATED FEATURES FOR TRAINING THE MODEL\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"train.csv\")\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "df[\"combined_imbalance\"] = df[\"imbalance_size\"] * df[\"imbalance_buy_sell_flag\"]\n",
        "df[\"fn_price_diff\"] = df[\"far_price\"] - df[\"near_price\"]\n",
        "df[\"nr_price_diff\"] = df[\"near_price\"] - df[\"reference_price\"]\n",
        "df[\"fr_price_diff\"] = df[\"far_price\"] - df[\"reference_price\"]\n",
        "df[\"im_size_diff\"] = df[\"imbalance_size\"] - df[\"matched_size\"]\n",
        "df[\"imb_ratio\"] = df[\"matched_size\"] - df[\"imbalance_size\"]\n",
        "df[\"bid_ask_spread\"] = (\n",
        "    df[\"bid_price\"] * df[\"bid_size\"] - df[\"ask_price\"] * df[\"ask_size\"]\n",
        ")\n",
        "\n",
        "output_file_path = \"train_with_new_features_new.csv\"\n",
        "df.to_csv(output_file_path, index=False)\n",
        "\n",
        "print(f\"File saved to {output_file_path}\")\n"
      ],
      "metadata": {
        "id": "ZGHw93jzbtXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pre-Processing Code for TCN Models"
      ],
      "metadata": {
        "id": "ahP86l1Ocv2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "\n",
        "# df = pd.read_csv(\"train.csv\") #For Without Feature Engineering\n",
        "df = pd.read_csv(\"train_with_new_features_new.csv\") #For With Feature Engineering\n",
        "\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "features = df.drop([\"target\", \"row_id\", \"time_id\"], axis=1)\n",
        "target = df[\"target\"]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "features_scaled = scaler.fit_transform(features)\n",
        "\n",
        "num_features = features_scaled.shape[1]\n",
        "X_train, X_test, y_train, y_test = train_test_split(features_scaled, target, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).view(-1, num_features, 1)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).view(-1, num_features, 1)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
        "\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4, pin_memory = True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4, pin_memory = True)\n"
      ],
      "metadata": {
        "id": "5WMVHnipbk53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Basic M-TCN Model"
      ],
      "metadata": {
        "id": "RKPL2OeccyU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UnitBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, dilation_rates):\n",
        "        super(UnitBlock, self).__init__()\n",
        "        self.dilated_conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, dilation=dilation_rates[0], padding=(kernel_size-1) * dilation_rates[0] // 2)\n",
        "        self.dilated_conv2 = nn.Conv1d(in_channels, out_channels, kernel_size, dilation=dilation_rates[1], padding=(kernel_size-1) * dilation_rates[1] // 2)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out1 = self.relu(self.dilated_conv1(x))\n",
        "        out2 = self.relu(self.dilated_conv2(x))\n",
        "        return out1 + out2\n",
        "\n",
        "class MTCN(nn.Module):\n",
        "    def __init__(self, num_features, num_outputs, out_channels, kernel_size, max_dilation, num_blocks):\n",
        "        super(MTCN, self).__init__()\n",
        "        self.blocks = nn.ModuleList()\n",
        "        current_dilation = 1\n",
        "        for _ in range(num_blocks):\n",
        "            dilation_rates = [current_dilation, current_dilation * 2]\n",
        "            self.blocks.append(UnitBlock(num_features if _ == 0 else out_channels, out_channels, kernel_size, dilation_rates))\n",
        "            current_dilation *= 4\n",
        "\n",
        "        self.output_layer = nn.Linear(out_channels, num_outputs)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "        x = x.mean(dim=2)\n",
        "        return self.output_layer(x)\n",
        "\n",
        "num_features = features_scaled.shape[1]\n",
        "kernel_size = 3\n",
        "out_channels = 32\n",
        "max_dilation = 8\n",
        "num_blocks = 1\n",
        "\n",
        "mtcn = MTCN(num_features, num_outputs=1, out_channels=out_channels, kernel_size=kernel_size, max_dilation=max_dilation, num_blocks=num_blocks)"
      ],
      "metadata": {
        "id": "gdAuvyKRb8TE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Residual M-TCN Model"
      ],
      "metadata": {
        "id": "EsV7_Gxsc6uM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class DilatedConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, dilation_rate, padding):\n",
        "        super(DilatedConvBlock, self).__init__()\n",
        "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size, dilation=dilation_rate, padding=padding)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.relu(self.conv(x))\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, num_units, max_dilation):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.units = nn.ModuleList()\n",
        "        for i in range(num_units):\n",
        "            dilation_rate = 2 ** i if i < max_dilation else 2 ** max_dilation\n",
        "            padding = (kernel_size - 1) * dilation_rate // 2\n",
        "            self.units.append(DilatedConvBlock(in_channels if i == 0 else out_channels, out_channels, kernel_size, dilation_rate, padding))\n",
        "\n",
        "        self.downsample = nn.Conv1d(in_channels, out_channels, kernel_size=1) if in_channels != out_channels else nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = self.downsample(x)\n",
        "        for unit in self.units:\n",
        "            x = unit(x)\n",
        "        return x + residual\n",
        "\n",
        "class MTCN(nn.Module):\n",
        "    def __init__(self, num_features, num_outputs, out_channels, kernel_size, max_dilation):\n",
        "        super(MTCN, self).__init__()\n",
        "        self.heads = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                ResidualBlock(1, out_channels, kernel_size, 3, max_dilation),\n",
        "                ResidualBlock(out_channels, out_channels, kernel_size, 4, max_dilation),\n",
        "                ResidualBlock(out_channels, out_channels, kernel_size, 3, max_dilation)\n",
        "            ) for _ in range(num_features)\n",
        "        ])\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc = nn.Linear(num_features * out_channels, num_outputs)\n",
        "\n",
        "    def forward(self, x):\n",
        "        outputs = []\n",
        "        for i in range(x.size(1)):\n",
        "            y = x[:, i:i+1, :]\n",
        "            y = self.heads[i](y)\n",
        "            outputs.append(self.flatten(y))\n",
        "        x = torch.cat(outputs, dim=1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "num_features = X_train_tensor.shape[1]\n",
        "kernel_size = 3\n",
        "out_channels = 32\n",
        "max_dilation = 8\n",
        "mtcn = MTCN(num_features, num_outputs=1, kernel_size=kernel_size, out_channels=out_channels, max_dilation=max_dilation)\n",
        "\n"
      ],
      "metadata": {
        "id": "8T4RKuBCcDHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LSTM Model with the Necessary Pre-Processing"
      ],
      "metadata": {
        "id": "rSlV5JJUdCWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# df = pd.read_csv(\"train.csv\") #For Without Feature Engineering\n",
        "df = pd.read_csv(\"train_with_new_features_new.csv\") #For With Feature Engineering\n",
        "\n",
        "print(df.head)\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "print(\"Rows with NaN values have been dropped.\")\n",
        "\n",
        "features = df.drop([\"target\", \"row_id\", \"time_id\"], axis=1)\n",
        "target = df[\"target\"]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "features_scaled = scaler.fit_transform(features)\n",
        "\n",
        "features_scaled = np.reshape(\n",
        "    features_scaled, (features_scaled.shape[0], 1, features_scaled.shape[1])\n",
        ")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    features_scaled, target, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "model = Sequential()\n",
        "model.add(\n",
        "    LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2]))\n",
        ")\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(50, return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1))\n",
        "\n",
        "learning_rate = 0.0001\n",
        "\n",
        "adam_optimizer = Adam(learning_rate=learning_rate)\n",
        "model.compile(optimizer=adam_optimizer, loss=\"mse\")\n",
        "\n",
        "\n",
        "for epoch in range(50):\n",
        "    try:\n",
        "        history = model.fit(\n",
        "            X_train,\n",
        "            y_train,\n",
        "            epochs=1,\n",
        "            batch_size=64,\n",
        "            validation_data=(X_test, y_test),\n",
        "            verbose=1,\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred in epoch {epoch+1}: {e}\")\n",
        "        continue\n",
        "\n",
        "\n",
        "predicted = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, predicted)\n",
        "mae = mean_absolute_error(y_test, predicted)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f\"Test MSE: {mse:.4f}\")\n",
        "print(f\"Test MAE: {mae:.4f}\")\n",
        "print(f\"Test RMSE: {rmse:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
        "plt.title(\"Training Loss Over Epochs\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.savefig(\"lstm1_lossplot_new_features_lr=0.0001.png\")\n",
        "plt.show()\n",
        "\n",
        "model.save(\"lstm_model_new_features.h5\")\n"
      ],
      "metadata": {
        "id": "FTY7ZITwcJxG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}